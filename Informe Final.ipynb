{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e138a43",
   "metadata": {},
   "source": [
    "# Informe de Solución del Proyecto Telecom \n",
    "\n",
    "## 1. Pasos Realizados y Omitidos\n",
    "Pasos realizados: \n",
    "1. Importación de datos y librerías: Se cargaron los cuatro archivos CSV y se revisaron sus dimensiones, muestras, columnas y tipos de datos.\n",
    "\n",
    "2. Limpieza de datos:\n",
    "    - Se convirtieron nombres de columnas a snake_case.\n",
    "    - Se corrigió el tipo de dato de total_charges, reemplazando valores vacíos por la mediana.\n",
    "    - Se identificaron y trataron valores nulos y duplicados.\n",
    "\n",
    "3. EDA\n",
    "\n",
    "    - Se evaluó la variable objetivo 'churned'.\n",
    "    - Se analizó la distribución de tarifas y métodos de pago, tipos de contrato, etc.\n",
    "      \n",
    "4. Creación de Variable Objetivo:\n",
    "\n",
    "   - Se generó la variable \"churned\" a partir de la columna \"end_date\".\n",
    "6. Unificación de Datos:\n",
    "\n",
    "    - Se combinaron los cuatro conjuntos de datos en un solo DataFrame completo.\n",
    "    - Se agregaron nuevas variables de fecha.\n",
    "\n",
    "7. Preprocesamiento:\n",
    "\n",
    "    - Se escalaron variables numéricas.\n",
    "    - Se codificaron variables catégoricas con target encoding y ordinal encoding.\n",
    "\n",
    "8. Modelado:\n",
    "\n",
    "   - Se entrenaron dos modelos LightGBM usando dos métodos de codificación.\n",
    "   - Se realizó GridSearchCV para optimizar hiperparámetros.\n",
    "   - Se evaluaron todos los modelos con métricas como ROC AUC, accuracy y F1.\n",
    "\n",
    "9. Interpretabilidad:\n",
    "\n",
    "   - Se aplicó SHAP para visualizar la importancia de las características.\n",
    "  \n",
    "Paso omitido: \n",
    "- No se utilizaron técnicas de reducción de dimensionalidad como PCA.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Dificultades Encontradas \n",
    "1. Valores vacíos como strings en \"total_charges\":\n",
    "   - Se reemplazaron por Nan y se imputaron con la mediana.\n",
    "\n",
    "2. Desbalanceo de Clases:\n",
    "   - Aunque inicialmente se consideró confiar en los modelos para manejarlo internamente, se decidió aplicar RandomOverSampler para mejorar la capacidad predictiva de modelos más simples como Regresión Logística.\n",
    "\n",
    "3. Selección de Codificación:\n",
    "    - Se evaluaron Ordinal vs. Target Encoding, y se eligió la que ogfrecía mejor desempeño para cada modelo.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Pasos Clave para la Solución de la Tarea\n",
    "- Creación de la variable 'churned', que convirtió un dato de fecha en una variable binaria.\n",
    "- Aplicación de RandomOverSampler, que mejoró el aprendizaje de los modelos más simples al balancear las clases.\n",
    "- Codificación adecuada de variables categóricas, que permitió representar información sin perder señal útil.\n",
    "- Ajuste de hiperparámetros, que optimizó el rendimiento de los modelos más complejos.\n",
    "- Interpretabilidad con SHAP, clave para entender qué factores influyen más en la cancelación.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Modelo Final y Nivel de Calidad\n",
    "El modelo final elegido fue LightGBM entrenado con Target Encoding. Se obtuvieron las siguientes métricas. \n",
    "\n",
    "    - ROC-AUC: ~0.91\n",
    "    - Accuracy: ~0.87\n",
    "    - F1-Score: ~0.75\n",
    "\n",
    "También se entrenaron: \n",
    "\n",
    "    - CatBoostClassifier: rendimiento similar sin embargo ligeramente menor pero con un tiempo de entrenamiento mucho mayor. \n",
    "    - Regresión Logística: Tuvo un desempeño aceptable pero inferior, especialmente ROC-AUC (~0.82), útil como modelo base para comparación. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
